{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunterno/PCDS/blob/main/P7A_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnwh-d01QDKI"
      },
      "source": [
        "___Inspiré par le Kernel :___\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ5cPIsdQDKK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN_BHstaQDKL"
      },
      "source": [
        "Société financière qui propose des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt.\n",
        "\n",
        "\n",
        "L’entreprise souhaite **développer un modèle de scoring de la probabilité de défaut de paiement du client** pour étayer la décision d'accorder ou non un prêt à un client potentiel en s’appuyant sur des sources de données variées (données comportementales, données provenant d'autres institutions financières, etc.).\n",
        "\n",
        "De plus, les chargés de relation client ont fait remonter le fait que les clients sont de plus en plus demandeurs de **transparence** vis-à-vis des décisions d’octroi de crédit. Cette demande de transparence des clients va tout à fait dans le sens des valeurs que l’entreprise veut incarner.\n",
        "\n",
        "Elle décide donc de développer un **dashboard interactif** pour que les chargés de relation client puissent à la fois expliquer de façon la plus transparente possible les décisions d’octroi de crédit, mais également permettre à leurs clients de disposer de leurs informations personnelles et de les explorer facilement. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgjiApsCQDKO"
      },
      "source": [
        "### Mission\n",
        "\n",
        "Présenter son travail de modélisation à l'oral\n",
        "\n",
        "\n",
        "- Réaliser un dashboard pour présenter son travail de modélisation\n",
        "-Rédiger une note méthodologique afin de communiquer sa démarche de modélisation\n",
        "-Utiliser un logiciel de version de code pour assurer l’intégration du modèle\n",
        "- Déployer un modèle via une API dans le Web\n",
        "\n",
        "Michaël, manager, incite à sélectionner un kernel Kaggle pour faciliter la préparation des données nécessaires à l’élaboration du modèle de scoring. L'idée est d'analyser ce kernel pour l'adapter aux besoins de la mission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnFYqR0zQDKP"
      },
      "source": [
        "### Spécifications du dashboard\n",
        "Michaël fourni un cahier des charges pour le dashboard interactif. Celui-ci devra a minima contenir les fonctionnalités suivantes :\n",
        "\n",
        "- Permettre de visualiser le score et l’interprétation de ce score pour chaque client de façon intelligible pour une personne non experte en data science.\n",
        "- Permettre de visualiser des informations descriptives relatives à un client (via un système de filtre).\n",
        "- Permettre de comparer les informations descriptives relatives à un client à l’ensemble des clients ou à un groupe de clients similaires."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIiSb8b4QDKS"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzmvCrG6QDLA",
        "outputId": "24b2c6fa-b8b8-42e3-e967-a3d380f33b54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['test']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ]
        }
      ],
      "source": [
        "#Essential data science libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import pickle\n",
        "import os\n",
        "%pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqEYO1gkQDLG"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_rows = 1000\n",
        "pd.options.display.max_columns = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HcYutU_QDLI"
      },
      "outputs": [],
      "source": [
        "#Graphing…\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.rcParams.update(\n",
        "    {\n",
        "     'xtick.labelsize':25,\n",
        "     'ytick.labelsize':25,\n",
        "     'axes.labelsize': 25,\n",
        "     'legend.fontsize': 25,\n",
        "     'axes.titlesize':45,\n",
        "     'axes.titleweight':'bold',\n",
        "     'axes.titleweight':'bold'\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fYxsjALQDLJ"
      },
      "source": [
        "## Chargement des données et Analyse exploratoire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC-vjlWvQDLL"
      },
      "source": [
        "### Data description from [Kaggle](https://www.kaggle.com/c/home-credit-default-risk/data) : \n",
        "\n",
        "\n",
        "#### application_{train|test}.csv\n",
        "This is the main table, broken into two files for Train (with TARGET) and Test (without TARGET).\n",
        "Static data for all applications. One row represents one loan in our data sample.\n",
        "\n",
        "#### bureau.csv\n",
        "All client's previous credits provided by other financial institutions that were reported to Credit Bureau (for clients who have a loan in our sample).\n",
        "For every loan in our sample, there are as many rows as number of credits the client had in Credit Bureau before the application date.\n",
        "\n",
        "#### bureau_balance.csv\n",
        "Monthly balances of previous credits in Credit Bureau.\n",
        "This table has one row for each month of history of every previous credit reported to Credit Bureau – i.e the table has (#loans in sample * # of relative previous credits * # of months where we have some history observable for the previous credits) rows.\n",
        "\n",
        "#### POS_CASH_balance.csv\n",
        "Monthly balance snapshots of previous POS (point of sales) and cash loans that the applicant had with Home Credit.\n",
        "This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credits * # of months in which we have some history observable for the previous credits) rows.\n",
        "\n",
        "#### credit_card_balance.csv\n",
        "Monthly balance snapshots of previous credit cards that the applicant has with Home Credit.\n",
        "This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credit cards * # of months where we have some history observable for the previous credit card) rows.\n",
        "\n",
        "#### previous_application.csv\n",
        "All previous applications for Home Credit loans of clients who have loans in our sample.\n",
        "There is one row for each previous application related to loans in our data sample.\n",
        "\n",
        "#### installments_payments.csv\n",
        "Repayment history for the previously disbursed credits in Home Credit related to the loans in our sample.\n",
        "There is a) one row for every payment that was made plus b) one row each for missed payment.\n",
        "One row is equivalent to one payment of one installment OR one installment corresponding to one payment of one previous Home Credit credit related to loans in our sample.\n",
        "\n",
        "#### HomeCredit_columns_description.csv\n",
        "This file contains descriptions for the columns in the various data files."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Fonctions\n",
        " \n",
        "###Fonction valmanque, paramètre (dataframe, pourcent,1 ou 0)\n",
        "###Imprime les colonnes avec le nombre de ligne avec valeurs ainsi que le pourcentage sans valeurs\n",
        "###puis retourne une liste contenant les nom de colonnes ayant un pourcentage inférieur a la valeur transmise.\n",
        "### retourne aussi le nombre de lignes non nulles correspondant à la colonne ValNa\n",
        " \n",
        "def valmanque(df,perct,imp):\n",
        "  # recherche des valeurs manquantes\n",
        "  NutriColonne=df.columns.values\n",
        "  ListeNaN=[]\n",
        "  ValNaN=df.isna().sum()\n",
        "  #nb Lignes\n",
        "  LigneNonNull=[]\n",
        "  NbLignes=len(df)\n",
        "  if imp == 1:\n",
        "    print(\"nombre de lignes :\",NbLignes)\n",
        "    print(\"nombre de ligne contenant des valeurs nul:\")\n",
        "    print(ValNaN)\n",
        "    print()\n",
        "    print(\"données par ligne après supression des valeurs null\")\n",
        " \n",
        "  i=0\n",
        "  i2=0\n",
        "  while i< len(df.columns):\n",
        "    LigneNonNull.append(NbLignes-ValNaN[i])\n",
        " \n",
        "    if imp == 1 and (ValNaN[i]*100/NbLignes)>=perct:\n",
        "        print('-----------------------------------------')\n",
        "        print(NutriColonne[i])\n",
        "        print(NbLignes-ValNaN[i],' nombres de lignes remplies')\n",
        "        print(ValNaN[i]*100/NbLignes,' % vide')\n",
        "    \n",
        "    if (ValNaN[i]*100/NbLignes)>=perct:\n",
        "      ListeNaN.append(NutriColonne[i])\n",
        "      i2=i2+1\n",
        "    i=i+1\n",
        "  print(i2,'sur',i,'variable avec plus de ',perct, 'pourcent de valeurs manquantes')\n",
        "  return(ListeNaN)\n",
        " \n",
        "#fonction donnant des données staistiques de bases en indiquant un dataframe et une liste de  noms de colonnes\n",
        "#retourne graphiques de corrélations et un tableau de résultat\n",
        " \n",
        "def Analyse_1(df,Var):  \n",
        "  # Analyse statistique de base (describe fait pareil,mais je voulais ma version...)\n",
        "  #création du dataframe\n",
        "  Resume = pd.DataFrame(columns=['minimum','maximum','somme','moyenne','médiane','mode,','varianceVar','varianceStd'])\n",
        " \n",
        "  for bcl in Var:\n",
        "   \n",
        "   mini=(df[bcl].min())\n",
        "   \n",
        "   maxi=(df[bcl].max())\n",
        " \n",
        "   total=(df[bcl].sum())\n",
        "  \n",
        "   moy=(df[bcl].mean())\n",
        "   \n",
        "   mediane=(df[bcl].median())\n",
        "  \n",
        "   Modee=(df[bcl].mode())\n",
        "   \n",
        "   Varr=(df[bcl].var(ddof=0))\n",
        "  \n",
        "   Stdd=(df[bcl].std(ddof=0))\n",
        "   \n",
        "   #création du dataframe de résultat  'ajout row'\n",
        "   df_new_row = pd.DataFrame(data=np.array([[mini,maxi,total,moy,mediane,Modee,Varr,Stdd]]), columns=['minimum','maximum','somme','moyenne','médiane','mode,','varianceVar','varianceStd'])\n",
        "   Resume = pd.concat([Resume,df_new_row], ignore_index=True)\n",
        " \n",
        "   plt.plot(df[bcl])\n",
        "   plt.show()\n",
        "  insert_index = 0\n",
        "  insert_colname = 'Nom'\n",
        "  insert_values = Var # this can be a numpy array too\n",
        "  Resume.insert(loc=insert_index, column=insert_colname, value=insert_values)\n",
        "  return(Resume)\n",
        " \n",
        "# Fonction créant un graphique de corellation en indiquant du dataframe et le nom de l'indicateur\n",
        "def correl(df,indicateur):\n",
        " \n",
        "  corr=df.corr(method=indicateur)\n",
        "  plt.figure(figsize = (16,5))\n",
        " \n",
        "  sns.heatmap(corr, \n",
        "            xticklabels=corr.columns,\n",
        "            yticklabels=corr.columns,\n",
        "            cmap='RdBu_r',\n",
        "            annot=True,\n",
        "            linewidth=1)\n",
        "  \n",
        "  def plot_stat(data, feature, title) : \n",
        "    \n",
        "    ax, fig = plt.subplots(figsize=(20,8)) \n",
        "    ax = sns.countplot(y=feature, data=data, order=data[feature].value_counts(ascending=False).index)\n",
        "    ax.set_title(title)\n",
        "\n",
        "    for p in ax.patches:\n",
        "                percentage = '{:.1f}%'.format(100 * p.get_width()/len(data[feature]))\n",
        "                x = p.get_x() + p.get_width()\n",
        "                y = p.get_y() + p.get_height()/2\n",
        "                ax.annotate(percentage, (x, y), fontsize=20, fontweight='bold')\n",
        "\n",
        "    show()\n",
        "\n",
        "    def plot_percent_target1(data, feature, title) : \n",
        "    \n",
        "    cat_perc = data[[feature, 'TARGET']].groupby([feature],as_index=False).mean()\n",
        "    cat_perc.sort_values(by='TARGET', ascending=False, inplace=True)\n",
        "    \n",
        "    ax, fig = plt.subplots(figsize=(20,8)) \n",
        "    ax = sns.barplot(y=feature, x='TARGET', data=cat_perc)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"\")\n",
        "    ax.set_ylabel(\"Percent of target with value 1\")\n",
        "\n",
        "    for p in ax.patches:\n",
        "                percentage = '{:.1f}%'.format(100 * p.get_width())\n",
        "                x = p.get_x() + p.get_width()\n",
        "                y = p.get_y() + p.get_height()/2\n",
        "                ax.annotate(percentage, (x, y), fontsize=20, fontweight='bold')\n",
        "\n",
        "    show()"
      ],
      "metadata": {
        "id": "6ZmJzG2Or5SW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "036b4797-8106-49cb-c83a-fcc46719f204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-118-e7682cc446bf>\"\u001b[0;36m, line \u001b[0;32m109\u001b[0m\n\u001b[0;31m    cat_perc = data[[feature, 'TARGET']].groupby([feature],as_index=False).mean()\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7n-hwVgQDLN"
      },
      "outputs": [],
      "source": [
        "print(\"CHECKLIST DATA EXPLORER :\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuihC9OsQDLO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "\n",
        "\n",
        "application_train = pd.read_csv(\"/content/drive/MyDrive/P7/data/application_train.csv\")\n",
        "application_test = pd.read_csv(\"/content/drive/MyDrive/P7/data/application_test.csv\")\n",
        "bureau = pd.read_csv(\"/content/drive/MyDrive/P7/data/bureau.csv\")\n",
        "#bureau_balance = pd.read_csv(\"/content/drive/MyDrive/P7/data/bureau_balance.csv\")\n",
        "#credit_card_balance = pd.read_csv(\"/content/drive/MyDrive/P7/data/credit_card_balance.csv\")\n",
        "installments_payments = pd.read_csv(\"/content/drive/MyDrive/P7/data/installments_payments.csv\")\n",
        "POS_CASH_balance = pd.read_csv(\"/content/drive/MyDrive/P7/data/POS_CASH_balance.csv\")\n",
        "previous_application = pd.read_csv(\"/content/drive/MyDrive/P7/data/previous_application.csv\")\n",
        "description = pd.read_csv(\"/content/drive/MyDrive/P7/data/HomeCredit_columns_description.csv\",encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V7B2KQFQDMk"
      },
      "outputs": [],
      "source": [
        "print(\"Explications des tables et colonnes :\")\n",
        "pd.set_option(\"max_colwidth\", 400)\n",
        "\n",
        "description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p5zONxmQDM4"
      },
      "source": [
        "### EDA application_train.csv | test.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=application_train.copy()\n",
        "test=application_test.copy()"
      ],
      "metadata": {
        "id": "wy6Z3gvsb_CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUKhums0QDM4"
      },
      "outputs": [],
      "source": [
        "print('taille de : train ', train.shape)\n",
        "print('taille de : test ', test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "la colonne manquante dans target et la colonne target"
      ],
      "metadata": {
        "id": "446kcQp7cQIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiQEQsgwQDM6"
      },
      "outputs": [],
      "source": [
        "#Distribution de la colonne'TARGET' entre les 1 crédit non remboursés et 0 crédit remboursés\n",
        "application_train['TARGET'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTb77xJ8QDM9"
      },
      "outputs": [],
      "source": [
        "ax, fig = plt.subplots(figsize=(20,8)) \n",
        "ax = sns.countplot(y='TARGET', data=train)\n",
        "ax.set_title(\"distribution des crédits accetpés et refusé\")\n",
        "\n",
        "for p in ax.patches:\n",
        "        percentage = '{:.1f}%'.format(100 * p.get_width()/len(application_train.TARGET))\n",
        "        x = p.get_x() + p.get_width()\n",
        "        y = p.get_y() + p.get_height()/2\n",
        "        ax.annotate(percentage, (x, y), fontsize=20, fontweight='bold')\n",
        "        \n",
        "show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NoJwWrnQDM-"
      },
      "source": [
        "La pluspart des prêts sont remboursés à temps. Une fois que nous entrons dans des modèles d'apprentissage automatique plus sophistiqués, nous pouvons pondérer les classes par leur représentation dans les données pour refléter ce déséquilibre."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykTBWDJEQDM-"
      },
      "source": [
        "### Types de colonnes\n",
        "Analyse rapide du type de features, mais surtout établir un aperçu afin de pouvoir poser une réflexion sur l'encodage des données catégorielles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zNcmmFqQDM_"
      },
      "outputs": [],
      "source": [
        "#Number of each type of column\n",
        "application_train.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#\n"
      ],
      "metadata": {
        "id": "BR8xe6M4lkn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Create a simple dataset with the train / test merge app\n",
        "#supression de la collonne taget pour avoir une liste sans la réponse\n",
        "\n",
        "liste_clients = train.append(test)\n",
        "del(train['TARGET'])\n",
        "\n",
        "print('Train:' + str(train.shape))\n",
        "print('Test:' + str(test.shape))\n",
        "print('liste_clients:' + str(liste_clients.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "9AukZwvRlLzP",
        "outputId": "e5ea902f-0d50-4e7f-b447-b2a3e836f07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TARGET'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-0f6cfa4f0127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Create a simple dataset with the train / test merge app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#supression de la collonne taget pour avoir une liste sans la réponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARGET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mliste_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3711\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3712\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3713\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3714\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TARGET'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANALISE"
      ],
      "metadata": {
        "id": "c6O1dwyTnRYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "liste_clients.describe()"
      ],
      "metadata": {
        "id": "6naHFBlcmV1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#57 sur 121 variable avec plus de  10 pourcent de valeurs manquantes\n"
      ],
      "metadata": {
        "id": "R1emadtBuqI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#donction perso pour valeur manquantes\n",
        "valmanque(liste_clients,10,0)"
      ],
      "metadata": {
        "id": "LiBI_aIWntQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#donction perso pour valeur manquantes\n",
        "valmanque(liste_clients,50,0)"
      ],
      "metadata": {
        "id": "2RYwRFdsu7U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"37 sur 121 variable avec plus de  50 pourcent de valeurs manquantes\n"
      ],
      "metadata": {
        "id": "mvVTVrL4vAbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features engineering\n",
        "Nous pourrais enrichir et retravailler, ou créer de nouvelle variables, mais ceci n'étant pas le centre du projet je me contenterai de suprimmer quelques colonnes que je trouve mal adaptées ou inapropriées.\n"
      ],
      "metadata": {
        "id": "5hbQ5c9vlWjC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Ffan15QDNA"
      },
      "source": [
        "La plupart des variables catégorielles ont un nombre relativement petit d'entrées uniques. Nous devrons trouver un moyen de traiter ces variables catégorielles…"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLA33X_fQDNA"
      },
      "source": [
        "[texte du lien](https://)### Valeurs manquantes\n",
        "En modélisation, des modèles tels que XGBoost peuvent gérer les valeurs manquantes sans imputation. Plusieurs alternatives seront possibles: remplacer les NaN, supprimer les colonnes avec un pourcentage élevé de valeurs manquantes (impossible de savoir à l'avance si ces colonnes seront utiles à notre modèle). Dans l'immédiat toutes les colonnes sont conservées…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5GJ28FFQDNB"
      },
      "outputs": [],
      "source": [
        "#Global view of the missing values (black)\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(train.notna(), cbar=False)\n",
        "show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWvJDzrAQDNB"
      },
      "source": [
        "Une synthèse des données manquantes un peu confuse du fait du grand nombre de variables, mais il se dégage un premier constat qui montre que les NaN sont plus fortement présentent sur les caractéristiques des habitats (et non sur les crédits), comme l'atteste le TOP 10 ci-après…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "aFh-OVMjQDNC"
      },
      "outputs": [],
      "source": [
        "def nan_check(data):\n",
        "    '''Check Missing Values'''\n",
        "    total = data.isnull().sum()\n",
        "    percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
        "    percent_2 = (np.round(percent_1, 2))\n",
        "    missing_data = pd.concat([total, percent_2], \n",
        "                             axis=1, keys=['Total', '%']).sort_values('%', ascending=False)\n",
        "    return missing_data\n",
        "\n",
        "print('TOP 20 Missing values from Training dataset')\n",
        "nan_check(liste_clients)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM utilise NA (NaN) pour représenter les valeurs manquantes par défaut. \n",
        "Nous allons garder cette option."
      ],
      "metadata": {
        "id": "1Kvx0sj9BxFg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfxSTxJ1QDND"
      },
      "source": [
        "#Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "oPU3R0Z5QDNH"
      },
      "outputs": [],
      "source": [
        "#How many days before the application the perso... (def. from HomeCredit_columns_description.csv)\n",
        "liste_clients['DAYS_EMPLOYED'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NWrAcq4gHW_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"%0.0f valeur 1000 ans 'days employed' \" % \n",
        "      len(liste_clients[liste_clients['DAYS_EMPLOYED'] == 365243]))\n"
      ],
      "metadata": {
        "id": "vDlVU7zMH79r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "365243 est la valeur maximale pour DAYS_EMPLOYED elle représente 1000 ans, il est curieux de retrouver ce chifres de très nombreuse fois\n",
        "celà ressemble à une valeur impossible placée là pour le programme de la banque."
      ],
      "metadata": {
        "id": "sHU-ZuWFDgGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Les seuls outliers semblent voulu"
      ],
      "metadata": {
        "id": "wPlmgR_RIcGv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgnk10TkQDNJ"
      },
      "source": [
        "### analyse \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eJeHK-PQDNK"
      },
      "source": [
        "**Loan types -** Distribution du type de prêts contractés + comparatif avec le pourcentage des prêts avec la valeur TARGET 1(prêt non retourné)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYUm43XpQDNL"
      },
      "source": [
        "Les prêts renouvelables ne représentent qu'une petite fraction (10%) du nombre total de prêts; dans le même temps, un plus grand nombre de crédits renouvelables, par rapport à leur fréquence, ne sont pas remboursés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gfR_nSkQDNL"
      },
      "source": [
        "**Client gender -** Bien que deux fois plus de prêt rembourser vienne de femmes cel me semble un facteur trop discriminant pour l'éthique de la banque colonne supprimée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "hvd7-srFQDNL"
      },
      "outputs": [],
      "source": [
        "#\n",
        "plot_stat(liste_clients, 'CODE_GENDER',\"sex distribution total\")\n",
        "print(\"                                   -------------------------------------------------------\")\n",
        "plot_percent_target1(liste_clients, 'CODE_GENDER',\"non emboursement entre les diférens sex\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ibUn7swQDNM"
      },
      "source": [
        "Le nombre de clients féminins est presque le double du nombre de clients masculins. En ce qui concerne le pourcentage de crédits en souffrance, les hommes ont plus de chances de ne pas rembourser leurs prêts (10%), comparativement aux femmes (7%)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XNA dot être prévue pour quelque chose qui n'a pas été utilisé"
      ],
      "metadata": {
        "id": "GNx8s5NBMhVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(liste_clients['CODE_GENDER'])\n"
      ],
      "metadata": {
        "id": "3Ch1S2JFJ0D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La pocession d'un véhicule ou non me semble non adéquate\n",
        "regardons"
      ],
      "metadata": {
        "id": "IO5RnGBxKH4f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs15dIcPQDNM"
      },
      "source": [
        "**Flag own car -** Distribution d'un impact possible entre les clients propriétaire d'un véhicule et ceux qui ne le sont pas…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0-kTvSsQDNN"
      },
      "outputs": [],
      "source": [
        "#FLAG_OWN_CAR\n",
        "plot_stat(application_train, 'FLAG_OWN_CAR',\"Personnes possédant une voiture\")\n",
        "print(\"                                   -------------------------------------------------------\")\n",
        "plot_percent_target1(application_train, 'FLAG_OWN_CAR',\"Non remboursement\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZApGlGyQDNN"
      },
      "source": [
        "#Comme j'y avais pensé celà n'est pas représentatif."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(liste_clients['FLAG_OWN_CAR'])"
      ],
      "metadata": {
        "id": "3Dr8F3S2oIId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoD40f12QDNy"
      },
      "source": [
        "## Features engineering\n",
        "On pourrais enrichir et retravailler, ou créer de nouvelle variables, mais ceci n'étant pas le centre du projet je me contenterai de suprimmer quelques colonnes que je trouve mal adaptées ou inapropriées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXybdp7mQDNd"
      },
      "source": [
        "Les deux jeux de données ont exactement le même format avec une seule différence, la TARGET dispo dans le train."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# le dataframe liste_clients est utilisé comme dataframe complet\n",
        "\n",
        "Mais nous utiliserons train pour l'entrainement et test pour le test puisque nous n'avons pas les données complêtes (test) ne contient pas le résultat."
      ],
      "metadata": {
        "id": "zfFXo_NzqhM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fg64jMLklBn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fstoeDarjAh0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss6ODk1iQDN3"
      },
      "source": [
        "## Preprocessing des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsjNKQygQDN4"
      },
      "source": [
        "### Split train / test data\n",
        "Il est nécessaire de commencer par la mise en place des données d'entrainement / test. On peut procéder en rappel avec les jeux de données application_train/test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDlPhzKMQDN5"
      },
      "source": [
        "### Encoding categorical features \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqHNRzj7QDN6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQrw4dqcQDN6"
      },
      "outputs": [],
      "source": [
        "# Create a label encoder object\n",
        "le = LabelEncoder()\n",
        "count = 0\n",
        "\n",
        "# Iterate through the columns\n",
        "for col in data_train:\n",
        "    # If 2 or fewer unique categories\n",
        "    if data_train.loc[:,col].dtype == 'object' and len(list(data_train.loc[:,col].unique())) <= 2:\n",
        "        # Train on the training data\n",
        "        le.fit(data_train.loc[:,col])\n",
        "        # Transform both training and testing data\n",
        "        data_train.loc[:,col] = le.transform(data_train.loc[:,col])\n",
        "        data_test.loc[:,col] = le.transform(data_test.loc[:,col])\n",
        "\n",
        "        count += 1\n",
        "            \n",
        "print('%d columns were label encoded.' % count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2dWiazjQDN6"
      },
      "outputs": [],
      "source": [
        "print('Training Features shape with categorical columns: ', data_train.shape)\n",
        "print('Testing Features shape with categorical columns: ', data_test.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "P7A_A.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yLA33X_fQDNA",
        "gfxSTxJ1QDND",
        "Wgnk10TkQDNJ",
        "PT3YQ6ZyQDNy",
        "WfGa5mGAQDNy",
        "QsjNKQygQDN4",
        "EDlPhzKMQDN5",
        "GrDXMHgBQDOJ",
        "FgXb3WDuQDOK",
        "bP4qOloPQDON"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}