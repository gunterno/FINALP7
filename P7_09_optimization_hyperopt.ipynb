{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLt8JXWNU5HB"
      },
      "source": [
        "# Problem definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZZAAUSLU5HM"
      },
      "source": [
        "LightGBM Bayesian Optimization HyperOpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ZoCIAnU5HN"
      },
      "source": [
        "basÃ© sur les sources suivantes:\n",
        "\n",
        "Sources:\n",
        "\n",
        "https://github.com/microsoft/LightGBM/issues/695#issuecomment-315591634\n",
        "\n",
        "https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/\n",
        "\n",
        "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
        "\n",
        "https://sites.google.com/view/lauraepp/parameters\n",
        "https://sanchom.wordpress.com/tag/average-precision/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_LDl9eSU5HP"
      },
      "outputs": [],
      "source": [
        "# basics\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# preprocess\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "# model\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# imbalanced\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "## hyperopt functions\n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample\n",
        "from functools import partial\n",
        "\n",
        "# evalue\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, average_precision_score, roc_auc_score, fbeta_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, auc, log_loss\n",
        "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, roc_curve, plot_roc_curve\n",
        "\n",
        "# resample\n",
        "from imblearn.over_sampling import ADASYN, SMOTE\n",
        "from imblearn.under_sampling import OneSidedSelection, NeighbourhoodCleaningRule, TomekLinks\n",
        "\n",
        "# turn off warning\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nhBNbkfKU5HS"
      },
      "outputs": [],
      "source": [
        "# Set model\n",
        "def instance_model(hyperparameters):\n",
        "    \n",
        "    # LightGBM classifier\n",
        "    if pd.DataFrame(hyperparameters.keys())[0][0] == 'lgbm':\n",
        "        model = LGBMClassifier(**hyperparameters['lgbm'], \n",
        "                            n_jobs = -1,\n",
        "                            random_state = 42,      \n",
        "                            objective = \"binary\", \n",
        "                            #categorical_feature = categorical_features_index,\n",
        "                            n_estimators = 9999999,\n",
        "                            bagging_freq = 1,       \n",
        "                            #is_unbalance = True,   \n",
        "                            learning_rate = 0.01)  \n",
        "       \n",
        "        # Resampling\n",
        "        # ADASYN: Adaptive synthetic sampling\n",
        "        if hyperparameters['lgbm']['sample'] == 'adasyn':\n",
        "            undersample = ADASYN(random_state=42)\n",
        "            if hyperparameters['lgbm']['power'] == True:\n",
        "                power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "                model = Pipeline([('sampling', undersample), \n",
        "                                  ('power', power), ('lgbm', model) ])\n",
        "            else: \n",
        "                model = Pipeline([('sampling', undersample), ('lgbm', model) ])\n",
        "                \n",
        "        # SMOTE: Synthetic Minority Oversampling Technique\n",
        "        if hyperparameters['lgbm']['sample'] == 'smote':\n",
        "            undersample = SMOTE()\n",
        "            if hyperparameters['lgbm']['power'] == True:\n",
        "                power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "                model = Pipeline([('sampling', undersample),\n",
        "                                  ('power', power), ('lgbm', model) ])\n",
        "            else: \n",
        "                model = Pipeline([('sampling', undersample), ('lgbm', model) ])\n",
        "                \n",
        "        # Tomek Links: remover exemplos ambiguos\n",
        "        elif hyperparameters['lgbm']['sample'] == 'tomek':\n",
        "            undersample = TomekLinks()\n",
        "            if hyperparameters['lgbm']['power'] == True:\n",
        "                power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "                model = Pipeline([('sampling', undersample), \n",
        "                                  ('power', power), ('lgbm', model) ])\n",
        "            else:\n",
        "                model = Pipeline([('sampling', undersample), ('lgbm', model) ])\n",
        "                \n",
        "        # Neighborhood Cleaning Rule for Undersampling: \n",
        "        # Condensed Nearest Neighbor + Edited Nearest Neighbors\n",
        "        elif hyperparameters['lgbm']['sample'] == 'ncr': \n",
        "            undersample  = NeighbourhoodCleaningRule(n_neighbors=3,\n",
        "                                                     threshold_cleaning=0.5)\n",
        "            if hyperparameters['lgbm']['power'] == True:\n",
        "                power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "                model = Pipeline([('sampling', undersample),\n",
        "                                  ('power', power), ('lgbm', model) ])\n",
        "            else:\n",
        "                model = Pipeline([('sampling', undersample), ('lgbm', model) ])\n",
        "                \n",
        "        # One-Sided Selection : \n",
        "        # Tomek Links + Condensed Nearest Neighbor \n",
        "        elif hyperparameters['lgbm']['sample'] == 'oss':\n",
        "            undersample = OneSidedSelection(n_neighbors=1, n_seeds_S=200)\n",
        "            if hyperparameters['lgbm']['power'] == True:\n",
        "                power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "                model = Pipeline([('sampling', undersample), \n",
        "                                  ('power', power), ('lgbm', model) ])\n",
        "            else:\n",
        "                model = Pipeline([('sampling', undersample), \n",
        "                                  ('lgbm', model) ])\n",
        "        ## No resampling\n",
        "        else:\n",
        "            if hyperparameters['lgbm']['power'] == True:\n",
        "                power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "                model = Pipeline([('sampling', None), \n",
        "                                  ('power', power), ('lgbm', model) ])\n",
        "            else:\n",
        "                model = Pipeline([('sampling', None), ('lgbm', model) ])\n",
        "     \n",
        "    return model\n",
        "\n",
        "def to_minimize(hyperparameters, features, target, fit_params):\n",
        "    # create an instance of the model \n",
        "    model = instance_model(hyperparameters)\n",
        "    \n",
        "    # train with cross-validation\n",
        "    resultado = cross_val_score(estimator = model, \n",
        "                                X = features, \n",
        "                                y = target, \n",
        "                                scoring = \"average_precision\",\n",
        "                                cv = cv, \n",
        "                                fit_params = fit_params,\n",
        "                                n_jobs = -1,\n",
        "                                error_score='raise')\n",
        "    \n",
        "    return -resultado.mean()\n",
        "\n",
        "# function to get the optimization history\n",
        "def extract_space_eval(hp_space, trial):\n",
        "    \n",
        "    ## get results\n",
        "    desempacota_trial = space_eval(space = hp_space, \n",
        "                                   hp_assignment = {k: v[0] for (k, v) in trial['misc']['vals'].items() if len(v) > 0})\n",
        "    \n",
        "    return desempacota_trial\n",
        "\n",
        "def unpack_dictionary(dictionary):\n",
        "    unpacked = {}\n",
        "    for (key, value) in dictionary.items():\n",
        "        if isinstance(value, dict):\n",
        "            unpacked = {**unpacked, **unpack_dictionary(value)}\n",
        "        else:\n",
        "            unpacked[key] = value\n",
        "            \n",
        "    return unpacked\n",
        "\n",
        "# Metrics to evaluate model\n",
        "def evalue_model(model, y_test, X_test, model_name):\n",
        "    # default cut off\n",
        "    threshold = 0.5\n",
        "    \n",
        "    # predict\n",
        "    pred_prob = model.predict_proba(X_test)\n",
        "    \n",
        "    # pr curve to best threshold\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, pred_prob[:, 1])\n",
        "\n",
        "    # calcule fscore\n",
        "    fscore_f2  = ((1+4)*precision*recall)/(4*precision+recall) # f2\n",
        "    fscore_f1  = (2*precision*recall)/(precision+recall) #f1\n",
        "    fscore_f05 = (1.25*precision*recall)/(0.25*precision+recall) #f05\n",
        "    \n",
        "    # get max\n",
        "    threshold_f2  = thresholds[np.argmax(fscore_f2)]\n",
        "    threshold_f1  = thresholds[np.argmax(fscore_f1)]\n",
        "    threshold_f05 = thresholds[np.argmax(fscore_f05)]\n",
        "    \n",
        "    # prob true class\n",
        "    pred_prob = [predicao[1] for predicao in pred_prob]\n",
        "    \n",
        "    # apply threshold 05\n",
        "    pred_class = [instancia >= threshold_f05 for instancia in pred_prob]\n",
        "    \n",
        "    # confusion matrix\n",
        "    cm = confusion_matrix(y_true = y_test, y_pred = pred_class)\n",
        "    \n",
        "    # metrics\n",
        "    dictionary = {'accuracy': accuracy_score(y_true = y_test,y_pred=pred_class),\n",
        "                  'F05': fbeta_score(y_true=y_test,y_pred=pred_class,beta=0.5),\n",
        "                  'F1': fbeta_score(y_true=y_test,y_pred=pred_class,beta=1),\n",
        "                  'F2': fbeta_score(y_true=y_test,y_pred=pred_class,beta=2),\n",
        "                  'recall': recall_score(y_true = y_test, y_pred = pred_class),\n",
        "                  'precision': precision_score(y_true=y_test,y_pred=pred_class),\n",
        "                  'tn': cm[0][0],\n",
        "                  'fn': cm[1][0],\n",
        "                  'tp': cm[1][1],\n",
        "                  'fp': cm[0][1],\n",
        "                  'logloss': log_loss(y_test, pred_prob),\n",
        "                  'threshold_f2': threshold_f2,\n",
        "                  'threshold_f05': threshold_f05,\n",
        "                  'threshold_f1': threshold_f1,\n",
        "                  'auc': roc_auc_score(y_true = y_test, y_score = pred_prob),\n",
        "                  'average_precision':average_precision_score(y_true=y_test,y_score=pred_prob),\n",
        "                  'aucpr': auc(recall, precision),\n",
        "                  'model_name': model_name}\n",
        "    \n",
        "    return dictionary\n",
        "\n",
        "def plot_auc_pr(name, labels, predictions,n=0.5, **kwargs):\n",
        "  p, r, _ = precision_recall_curve(labels, predictions)\n",
        "\n",
        "  plt.plot(100*r, 100*p, label=name, linewidth=2, **kwargs)\n",
        "  plt.xlabel('Recall [%]')\n",
        "  plt.ylabel('Precision [%]')\n",
        "  plt.xlim([-0.5,100])\n",
        "  plt.title('Precision-Recall Curve')\n",
        "  plt.ylim([20,100.5])\n",
        "  plt.grid(True)\n",
        "  ax = plt.gca()\n",
        "  ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K848OGK4U5Ha"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('drive/MyDrive/data/P7/clientsdata.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R762OroeU5Hb"
      },
      "outputs": [],
      "source": [
        "liste=df.columns\n",
        "#Label Encoding for object to numeric conversion\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "for  bcl in liste:\n",
        "    df[bcl] = le.fit_transform(df[bcl].astype(str))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ-CTwgQU5Hc"
      },
      "source": [
        "# Modeling\n",
        "\n",
        "Separate explanatory variables from the target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSpUig8lU5Hd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhDFagGaU5He"
      },
      "outputs": [],
      "source": [
        "X = df.drop('TARGET', axis=1)\n",
        "y = df['TARGET']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train = pd.DataFrame(X_train.values, columns=X.columns)\n",
        "X_test  = pd.DataFrame(X_test.values, columns=X.columns)\n",
        "y_train = y_train.values\n",
        "y_test  = y_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMugNF5BU5Hf"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "print(\"Train: non_remboursement =\", sum(y_train), \"remboursement =\", len(y_train) - sum(y_train))\n",
        "print(\"Val:   non_remboursement =\", sum(y_val), \" remboursement =\", len(y_val) - sum(y_val))\n",
        "print(\"Test:  non_remboursement =\", sum(y_test), \" remboursement =\", len(y_test) - sum(y_test))\n",
        "\n",
        "eval_set = [(pd.DataFrame(X_val), pd.DataFrame(y_val))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjjD2EmJU5Hf"
      },
      "source": [
        "Define cross-validation method as stratified (due to unbalanced database) and shuffle to avoid ordering bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKRLaFZTU5Hh"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45fMTDRbU5Hh"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuatM_MHU5Hi"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "model_lgbm = LGBMClassifier(n_jobs = -1, random_state = 42, objective = \"binary\",\n",
        "                            #categorical_feature= categorical_features_index,\n",
        "                            n_estimators = 9999999,\n",
        "                            bagging_freq = 1,\n",
        "                            #boosting = \"dart\",\n",
        "                            learning_rate = 0.01,\n",
        "                            is_unbalance = True)\n",
        "\n",
        "fit_params={'lgbm__early_stopping_rounds': 100, \n",
        "            'lgbm__eval_metric': 'average_precision',\n",
        "            'lgbm__verbose': True,\n",
        "            'lgbm__eval_set': eval_set}\n",
        "\n",
        "undersample = None\n",
        "\n",
        "model_lgbm_baseline = Pipeline([('sample', undersample), \n",
        "                                ('lgbm', model_lgbm) ])\n",
        "\n",
        "model_lgbm_baseline_cv = cross_val_score(model_lgbm_baseline, X_train, y_train, \n",
        "                                        cv = cv, \n",
        "                                        scoring = \"average_precision\", \n",
        "                                        fit_params = fit_params, \n",
        "                                        n_jobs=-1, \n",
        "                                         error_score='raise')\n",
        "\n",
        "print(\"cross-validation Average Precision:\",f\"{model_lgbm_baseline_cv.mean():.3f} STD:{model_lgbm_baseline_cv.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxDSuDJOU5Hi"
      },
      "source": [
        "## Bayes Optimization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi-wnqXTU5Hj"
      },
      "outputs": [],
      "source": [
        "scale_pos_weight_max = int((len(y_train) - sum(y_train)) / sum(y_train))\n",
        "scale_pos_weight_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7VOTVKEU5Hj"
      },
      "outputs": [],
      "source": [
        "# choices source: https://github.com/microsoft/LightGBM/issues/695#issuecomment-315591634\n",
        "hp_space_lgbm = {\n",
        "    'lgbm': {\n",
        "        # number of trees and learning rate -------------\n",
        "        #'n_estimators': ho_scope.int(hp.quniform('n_estimators',100,600,100)), # eval autotune\n",
        "        #'learning_rate': hp.loguniform('learning_rate',np.log(1e-5),np.log(0.05)), # eval autotune\n",
        "        # tree depth ------------------------------------\n",
        "        #'max_depth':  ho_scope.int(hp.quniform('max_depth',2,12,1)),\n",
        "        #'num_leaves': hp.choice(label = 'num_leaves', options = [15, 31, 63, 127, 255, 511, 1023, 2047, 4095]),\n",
        "        #'min_child_weight':  ho_scope.int(hp.quniform('min_child_weight',0,X_train.shape[0]/100,1)),\n",
        "        # conservative update step ----------------------\n",
        "        ##'max_delta_step': ho_scope.int(hp.quniform('max_delta_step',1,10,1)),\n",
        "        # sampling --------------------------------------\n",
        "        'subsample': hp.uniform('subsample',0.4,1), \n",
        "        'colsample_bytree': hp.uniform('colsample_bytree',0.4,1),\n",
        "        #'feature_fraction': hp.uniform('feature_fraction',0.2,0.7),\n",
        "        # regularization --------------------------------\n",
        "        'reg_lambda': hp.loguniform('reg_lambda',np.log(1e-4),np.log(10)),\n",
        "        'reg_alpha': hp.loguniform('reg_alpha',np.log(1e-4),np.log(10)),\n",
        "        ##'min_gain_to_split': hp.loguniform('min_gain_to_split',np.log(1e-4),np.log(2)),\n",
        "        # specific lgbm ---------------------------------\n",
        "        #'min_child_samples': ho_scope.int(hp.quniform('min_child_samples',10,500,100)),\n",
        "        # set weights for balancing ---------------------\n",
        "        'scale_pos_weight' : ho_scope.int(hp.loguniform('scale_pos_weight',np.log(1),np.log(scale_pos_weight_max))),\n",
        "        # Dart Booster ----------------------------------\n",
        "        #'drop_rate': hp.uniform('drop_rate',0,1),\n",
        "        #'skip_drop': hp.uniform('skip_drop',0,1)\n",
        "        # Pipeline parameters ---------------------------\n",
        "        # Sampling\n",
        "        'sample':  hp.choice(label = 'sample', options = [None, 'tomek', 'ncr','oss', 'smote']),\n",
        "        # Boxcox\n",
        "        'power': hp.choice(label = 'power', options = [False, True])\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9dC0oKvU5Hl"
      },
      "outputs": [],
      "source": [
        "## criando instancia do Trials\n",
        "interactions_lgbm = Trials()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzAgzOoAU5Hl"
      },
      "outputs": [],
      "source": [
        "fit_params={'lgbm__early_stopping_rounds': 100,\n",
        "            'lgbm__eval_metric': 'average_precision',\n",
        "            'lgbm__verbose': False,\n",
        "            'lgbm__eval_set': eval_set}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmyCSYAPU5Hm"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "## run optimization\n",
        "optimization = fmin(fn = partial(to_minimize, features = X_train, target = y_train, fit_params = fit_params),\n",
        "                  space = hp_space_lgbm, \n",
        "                  algo = tpe.suggest,\n",
        "                  trials = interactions_lgbm,\n",
        "                  max_evals = int(2), \n",
        "                  rstate = np.random.RandomState(42))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jam6LB6NU5Hm"
      },
      "outputs": [],
      "source": [
        "## save history \n",
        "lgbm_history = pd.DataFrame([unpack_dictionary(extract_space_eval(hp_space_lgbm, x)) for x in interactions_lgbm.trials])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA0bALoLU5Hm"
      },
      "outputs": [],
      "source": [
        "print(lgbm_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMqAEsPKU5Hn"
      },
      "source": [
        "## Understand train results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjbuBu3RU5Hn"
      },
      "outputs": [],
      "source": [
        "optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnOe2PePU5Hn"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x = lgbm_history.index,  data = lgbm_history)\n",
        "plt.title('Optimization History')\n",
        "plt.xlabel(xlabel = 'Interaction')\n",
        "plt.ylabel(ylabel = 'Average Precision')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP-UCK67U5Ho"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = 'sample', data = pd.DataFrame(lgbm_history['sample'].apply(lambda x: \"None\" if x == None else x)))\n",
        "plt.title('Times each criterion was selected')\n",
        "plt.xlabel(xlabel = 'sample')\n",
        "plt.ylabel(ylabel = 'Interactions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFdkm8EiU5Ho"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = 'power', data = lgbm_history)\n",
        "plt.title('Times each criterion was selected')\n",
        "plt.xlabel(xlabel = 'YeoJhonson')\n",
        "plt.ylabel(ylabel = 'Interactions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtEicc1qU5Ho",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "selected_hyperparameters = space_eval(space = hp_space_lgbm, hp_assignment = optimization)\n",
        "selected_hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk775Yo1U5Hp"
      },
      "outputs": [],
      "source": [
        "model_lgbm_bayeshp = instance_model(hyperparameters=selected_hyperparameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHfjxSutU5Hp"
      },
      "source": [
        "# Evalue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf0OLn42U5Hp"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "classifiers = {\n",
        "    \"LGBMBaseline\": model_lgbm_baseline,\n",
        "    \"LGBMBayesOpt\": model_lgbm_bayeshp\n",
        "}\n",
        "\n",
        "# df to store metrics \n",
        "results_lgbm = pd.DataFrame(columns= ['metric', 'model_name', 'aucpr', 'average_precision', 'auc', 'accuracy', 'F05', 'F1', 'F2', 'recall', 'precision', 'tn', 'fn', 'tp', 'fp', 'logloss', 'threshold_f2', 'threshold_f05', 'threshold_f1'])\n",
        "\n",
        "# df to save predictions\n",
        "pred_df = pd.DataFrame(y_test,index=None)\n",
        "\n",
        "for key, classifier in classifiers.items():\n",
        "    print(\"Running\", key)\n",
        "    model          = classifier.fit(X_train, y_train, \n",
        "                                    lgbm__early_stopping_rounds= 100, \n",
        "                                    lgbm__eval_metric= 'average_precision',\n",
        "                                    lgbm__verbose = 0,\n",
        "                                    lgbm__eval_set= eval_set)\n",
        "    pred_df[key]   = model.predict_proba(X_test)[:,1]\n",
        "    training_score = evalue_model(model,y_test, X_test, key)\n",
        "    df             = pd.DataFrame(training_score.items(), columns = [\"metric\", \"value\"])\n",
        "    results_lgbm   = results_lgbm.append(df.set_index('metric').T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHLyEPD9U5Hq"
      },
      "outputs": [],
      "source": [
        "results_lgbm.drop('metric', axis=1).reset_index().drop('index', axis=1).sort_values(\"aucpr\", ascending = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_name\taucpr\taverage_precision\tauc\taccuracy\tF05\tF1\tF2\trecall\tprecision\ttn\tfn\ttp\tfp\tlogloss\tthreshold_f2\tthreshold_f05\tthreshold_f1\n",
        "1\tLGBMBayesOpt\t0.249034\t0.249211\t0.759235\t0.901371\t0.304126\t0.267922\t0.23942\t0.223565\t0.334237\t54327\t3855\t1110\t2211\t0.245539\t0.08685\t0.251061\t0.15111\n",
        "0\tLGBMBaseline\t0.204705\t0.193407\t0.718382\t0.89342\t0.249562\t0.223065\t0.201654\t0.189527\t0.271025\t54007\t4024\t941\t2531\t0.27711\t0.101407\t0.113087\t0.107935"
      ],
      "metadata": {
        "id": "ewDWD_5dAuG7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mqdZYfLU5Hq"
      },
      "source": [
        "AUCPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmm2YZgWU5Hq"
      },
      "outputs": [],
      "source": [
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "plt.figure(figsize=(12,20))\n",
        "sns.set_style(\"whitegrid\")\n",
        "plot_auc_pr(\"LGBMBaseline\", y_test, pred_df[\"LGBMBaseline\"], color=colors[0])\n",
        "plot_auc_pr(\"LGBMBayesOpt\", y_test ,pred_df[\"LGBMBayesOpt\"], color=colors[1],linestyle='--')\n",
        "plt.legend(loc='lower left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNapgNkmU5Hr"
      },
      "outputs": [],
      "source": [
        "plt.rcdefaults()\n",
        "fig, ax = plt.subplots()\n",
        "plt.figure(figsize=(20,20))\n",
        "ax.barh(X.columns[np.argsort(model_lgbm_bayeshp.steps[1][1].feature_importances_)][::-1], \n",
        "        sorted(model_lgbm_bayeshp.steps[1][1].feature_importances_, reverse=True),\n",
        "        align='center')\n",
        "ax.set_yticks(X.columns)\n",
        "ax.invert_yaxis() \n",
        "ax.set_xlabel('Importance')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n"
      ],
      "metadata": {
        "id": "l_JUtLWP6OEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "clf1 = lgb.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bylevel=0.8,\n",
        "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
        "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
        "               min_split_gain=0.0, n_estimators=1000, n_jobs=-1, num_leaves=31,\n",
        "               objective=None, random_state=44, reg_alpha=0.0, reg_lambda=0.0,\n",
        "               scale_pos_weight=1, silent=False, subsample=0.8,\n",
        "               subsample_for_bin=200000, subsample_freq=0)  \n",
        "\n",
        "model=clf1.fit(X,y,sample_weight=None)"
      ],
      "metadata": {
        "id": "ARFVxK9p6bA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the knn_model to disk\n",
        "import pickle\n",
        "filename = 'drive/MyDrive/data/P7/clientsdata.pkl'\n",
        "pickle.dump(clf1, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "xWa6bbEw85a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr,tpr,_ = metrics.roc_curve(yTest,yPredLGB)\n",
        "rocAuc = metrics.auc(fpr, tpr)\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title('ROC Curve')\n",
        "sns.lineplot(fpr, tpr, label = 'AUC for LightGBM Model = %0.2f' % rocAuc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ksah3sQFApng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "PEtHcou6svRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "classifier_shap = shap.KernelExplainer(sklearn_regressor.predict, X_train)\n",
        "\n",
        "shap_results = classifier_shap.shap_values(X_test.iloc[0])\n",
        "\n",
        "shap.waterfall_plot(classifier_shap.expected_value,shap_values,X_test.iloc[0])\n"
      ],
      "metadata": {
        "id": "t5xS45M2E-Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guEL0uhWU5Hr"
      },
      "source": [
        "Sources:\n",
        "\n",
        "- <https://github.com/microsoft/LightGBM/issues/695#issuecomment-315591634>\n",
        "- <https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/>\n",
        "- <https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/>\n",
        "- <https://sites.google.com/view/lauraepp/parameters>\n",
        "- <https://sanchom.wordpress.com/tag/average-precision/>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copie de P7-optimization-hyperopt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}